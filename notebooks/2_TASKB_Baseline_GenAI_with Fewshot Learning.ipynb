{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81691586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from typing import List, Dict\n",
    "import torch\n",
    "import subprocess\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c8d9ec",
   "metadata": {},
   "source": [
    "## Number of few shot examples = 3 / 5 /10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27cace87",
   "metadata": {},
   "outputs": [],
   "source": [
    "FINE_LABELS = [\n",
    "        \"Ad-hominem\", \"Appeal-to-authority\", \"Appeal-to-emotion\",\n",
    "        \"Causal-oversimplification\", \"Cherry-picking\", \"Circular-reasoning\",\n",
    "        \"Doubt\", \"Evading-the-burden-of-proof\", \"False-analogy\",\n",
    "        \"False-dilemma\", \"Flag-waving\", \"Hasty-generalization\",\n",
    "        \"Loaded-language\", \"Name-calling-or-labelling\", \"Red-herring\",\n",
    "        \"Slippery-slope\", \"Slogan\", \"Strawman\",\n",
    "        \"Thought-terminating-cliches\", \"Vagueness\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f7d2a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_Name = \"Qwen/Qwen2.5-3B-Instruct\"\n",
    "# Model_Name = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "# Model_Name = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "# Model_Name = \"google/gemma-3n-E2B-it\"\n",
    "# Model_Name = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "# Model_Name = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "# Model_Name = \"HuggingFaceTB/SmolLM2-1.7B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a48f750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(model_name=Model_Name, use_cpu=False, use_4bit=False):\n",
    "    device = \"cuda\" if torch.cuda.is_available() and not use_cpu else \"cpu\"\n",
    "    print(f\"Loading model on device: {device}\")\n",
    "\n",
    "    if use_4bit:\n",
    "        bnb_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_compute_dtype=torch.float16,\n",
    "        )\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            quantization_config=bnb_config,\n",
    "            device_map=\"auto\",\n",
    "            low_cpu_mem_usage=True,\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "    else:\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            device_map=\"auto\",\n",
    "            low_cpu_mem_usage=True,\n",
    "            torch_dtype=torch.float16,\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    return model, tokenizer, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57b1da6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_conll_file(filepath: str) -> List[Dict]:\n",
    "    posts = []\n",
    "    current_post = None\n",
    "    \n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.rstrip('\\n')\n",
    "            \n",
    "            if line.startswith(\"# post_id = \"):\n",
    "                if current_post:\n",
    "                    posts.append(current_post)\n",
    "                current_post = {\n",
    "                    'post_id': line.split(\" = \")[1],\n",
    "                    'date': '',\n",
    "                    'topic': '',\n",
    "                    'text': '',\n",
    "                    'tokens': [],\n",
    "                    'bio_tags_a1': [],\n",
    "                    'bio_tags_a2': []\n",
    "                }\n",
    "            elif line.startswith(\"# post_date = \"):\n",
    "                current_post['date'] = line.split(\" = \")[1]\n",
    "            elif line.startswith(\"# post_topic_keywords = \"):\n",
    "                current_post['topic'] = line.split(\" = \")[1]\n",
    "            elif line.startswith(\"# post_text = \"):\n",
    "                current_post['text'] = line.split(\" = \")[1]\n",
    "            elif len(line.strip()) == 0:\n",
    "                if current_post and current_post['tokens']:\n",
    "                    current_post['spans_a1'] = bio_to_spans(\n",
    "                        current_post['tokens'], current_post['bio_tags_a1']\n",
    "                    )\n",
    "                    current_post['spans_a2'] = bio_to_spans(\n",
    "                        current_post['tokens'], current_post['bio_tags_a2']\n",
    "                    )\n",
    "                    posts.append(current_post)\n",
    "                    current_post = None\n",
    "            elif current_post is not None:\n",
    "                parts = line.split('\\t')\n",
    "                if len(parts) >= 4:\n",
    "                    current_post['tokens'].append(parts[1])\n",
    "                    current_post['bio_tags_a1'].append(parts[2])\n",
    "                    current_post['bio_tags_a2'].append(parts[3])\n",
    "    \n",
    "    if current_post and current_post['tokens']:\n",
    "        current_post['spans_a1'] = bio_to_spans(\n",
    "            current_post['tokens'], current_post['bio_tags_a1']\n",
    "        )\n",
    "        current_post['spans_a2'] = bio_to_spans(\n",
    "            current_post['tokens'], current_post['bio_tags_a2']\n",
    "        )\n",
    "        posts.append(current_post)\n",
    "    \n",
    "    print(f\"Parsed {len(posts)} posts from {filepath}\")\n",
    "    return posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f101318",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bio_to_spans(tokens: List[str], bio_tags: List[str]) -> List[Dict]:\n",
    "    active_spans = {}\n",
    "    completed_spans = []\n",
    "    \n",
    "    for idx, (token, bio_tag_str) in enumerate(zip(tokens, bio_tags)):\n",
    "        bio_tags_list = bio_tag_str.split('|')\n",
    "        current_labels = set()\n",
    "        \n",
    "        for bio_tag in bio_tags_list:\n",
    "            bio_tag = bio_tag.strip()\n",
    "            if bio_tag.startswith(\"B-\"):\n",
    "                label = bio_tag[2:]\n",
    "                current_labels.add(label)\n",
    "                \n",
    "                if label in active_spans:\n",
    "                    span = active_spans[label]\n",
    "                    completed_spans.append({\n",
    "                        'label': label,\n",
    "                        'start_tok': span['start_tok'],\n",
    "                        'end_tok': idx - 1,\n",
    "                        'text': \" \".join(span['tokens'])\n",
    "                    })\n",
    "                \n",
    "                active_spans[label] = {'start_tok': idx, 'tokens': [token]}\n",
    "                \n",
    "            elif bio_tag.startswith(\"I-\"):\n",
    "                label = bio_tag[2:]\n",
    "                current_labels.add(label)\n",
    "                if label in active_spans:\n",
    "                    active_spans[label]['tokens'].append(token)\n",
    "                else:\n",
    "                    active_spans[label] = {'start_tok': idx, 'tokens': [token]}\n",
    "        \n",
    "        labels_to_close = set(active_spans.keys()) - current_labels\n",
    "        for label in labels_to_close:\n",
    "            span = active_spans[label]\n",
    "            completed_spans.append({\n",
    "                'label': label,\n",
    "                'start_tok': span['start_tok'],\n",
    "                'end_tok': idx - 1,\n",
    "                'text': \" \".join(span['tokens'])\n",
    "            })\n",
    "            del active_spans[label]\n",
    "    \n",
    "    for label, span in active_spans.items():\n",
    "        completed_spans.append({\n",
    "            'label': label,\n",
    "            'start_tok': span['start_tok'],\n",
    "            'end_tok': len(tokens) - 1,\n",
    "            'text': \" \".join(span['tokens'])\n",
    "        })\n",
    "    \n",
    "    return completed_spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0e7c931",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_for_model(prompt: str, tokenizer) -> str:\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    if hasattr(tokenizer, \"apply_chat_template\"):\n",
    "        try:\n",
    "            return tokenizer.apply_chat_template(\n",
    "                messages, tokenize=False, add_generation_prompt=True\n",
    "            )\n",
    "        except Exception:\n",
    "            return prompt\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15fa3b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(prompt: str, model, tokenizer, device, max_tokens: int = 1024, temperature: float = 0.1) -> str:\n",
    "    text = format_for_model(prompt, tokenizer)\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True).to(device)\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_tokens,\n",
    "            temperature=temperature,\n",
    "            top_p=0.95,\n",
    "            do_sample=True if temperature > 0 else False,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=tokenizer.pad_token_id or tokenizer.eos_token_id,\n",
    "        )\n",
    "    \n",
    "    generated = outputs[0][inputs[\"input_ids\"].shape[1]:]\n",
    "    response = tokenizer.decode(generated, skip_special_tokens=True)\n",
    "    \n",
    "    del inputs, outputs, generated\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "333ad817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_spans_from_response(response: str) -> List[Dict]:\n",
    "    spans = []\n",
    "    response = re.sub(r'```json\\s*', '', response)\n",
    "    response = re.sub(r'```\\s*', '', response)\n",
    "    response = response.strip()\n",
    "    \n",
    "    # Strategy 1: Try JSON array\n",
    "    try:\n",
    "        # Find JSON array\n",
    "        start = response.find(\"[\")\n",
    "        end = response.rfind(\"]\") + 1\n",
    "        if start != -1 and end > start:\n",
    "            json_str = response[start:end]\n",
    "            data = json.loads(json_str)\n",
    "            if isinstance(data, list):\n",
    "                spans = data\n",
    "                print(f\" Extracted from JSON array\")\n",
    "    except Exception as e:\n",
    "        print(f\" JSON array parsing failed: {e}\")\n",
    "    \n",
    "    # Strategy 2: Try JSON object with \"spans\" key\n",
    "    if not spans:\n",
    "        try:\n",
    "            start = response.find(\"{\")\n",
    "            end = response.rfind(\"}\") + 1\n",
    "            if start != -1 and end > start:\n",
    "                json_str = response[start:end]\n",
    "                data = json.loads(json_str)\n",
    "                if \"spans\" in data:\n",
    "                    spans = data[\"spans\"]\n",
    "                    print(f\" Extracted from JSON object\")\n",
    "        except Exception as e:\n",
    "            print(f\" JSON object parsing failed: {e}\")\n",
    "    \n",
    "    # Strategy 3: Line-by-line extraction (for malformed JSON)\n",
    "    if not spans:\n",
    "        print(f\" Trying line-by-line extraction...\")\n",
    "        for line in response.split('\\n'):\n",
    "            text_match = re.search(r'\"text\"\\s*:\\s*\"([^\"]+)\"', line)\n",
    "            label_match = re.search(r'\"label\"\\s*:\\s*\"([^\"]+)\"', line)\n",
    "            if text_match and label_match:\n",
    "                spans.append({\n",
    "                    \"text\": text_match.group(1),\n",
    "                    \"label\": label_match.group(1)\n",
    "                })\n",
    "        if spans:\n",
    "            print(f\" Extracted {len(spans)} spans line-by-line\")\n",
    "    \n",
    "    # Validate spans\n",
    "    valid_spans = []\n",
    "    for span in spans:\n",
    "        if not isinstance(span, dict):\n",
    "            continue\n",
    "        \n",
    "        text = span.get(\"text\", \"\").strip()\n",
    "        label = span.get(\"label\", \"\").strip().replace(\" \", \"-\").replace(\"_\", \"-\")\n",
    "        \n",
    "        if not text or not label:\n",
    "            continue\n",
    "        \n",
    "        # Match label\n",
    "        if label in FINE_LABELS:\n",
    "            valid_spans.append({\"text\": text, \"label\": label})\n",
    "        else:\n",
    "            for fine_label in FINE_LABELS:\n",
    "                if fine_label.lower() == label.lower():\n",
    "                    valid_spans.append({\"text\": text, \"label\": fine_label})\n",
    "                    break\n",
    "    \n",
    "    return valid_spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ad9f5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_few_shot_examples(posts: List[Dict], n_examples_per_label: int = 3, \n",
    "                           annotator: str = \"a1\") -> Dict[str, List[str]]:\n",
    "    examples = defaultdict(list)\n",
    "    spans_key = f'spans_{annotator}'\n",
    "    \n",
    "    # Collect all spans per label\n",
    "    label_spans = defaultdict(list)\n",
    "    for post in posts:\n",
    "        for span in post.get(spans_key, []):\n",
    "            label = span['label']\n",
    "            text = span['text'].strip()\n",
    "            if label in FINE_LABELS and len(text.split()) >= 2:  # At least 2 words\n",
    "                label_spans[label].append(text)\n",
    "    \n",
    "    # Select diverse examples\n",
    "    for label, span_list in label_spans.items():\n",
    "        # Remove duplicates\n",
    "        unique_spans = list(set(span_list))\n",
    "        \n",
    "        # Sort by length to get variety\n",
    "        sorted_spans = sorted(unique_spans, key=len)\n",
    "        \n",
    "        # Pick examples from different length buckets\n",
    "        selected = []\n",
    "        if len(sorted_spans) <= n_examples_per_label:\n",
    "            selected = sorted_spans\n",
    "        else:\n",
    "            step = len(sorted_spans) // n_examples_per_label\n",
    "            for i in range(n_examples_per_label):\n",
    "                idx = min(i * step, len(sorted_spans) - 1)\n",
    "                selected.append(sorted_spans[idx])\n",
    "        \n",
    "        examples[label] = selected\n",
    "    \n",
    "    print(f\"\\nBuilt few-shot examples for {len(examples)} labels:\")\n",
    "    for label in FINE_LABELS:\n",
    "        if label in examples:\n",
    "            print(f\"  {label}: {len(examples[label])} examples\")\n",
    "    \n",
    "    return dict(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "905e1fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_few_shot_prompt(text: str, examples: Dict[str, List[str]], \n",
    "                          max_examples_per_label: int = 3) -> str:    \n",
    "    prompt = \"\"\"You are an expert in identifying logical fallacies in text. \n",
    "Your task is to extract ALL text spans that contain fallacies and label them.\n",
    "\n",
    "AVAILABLE FALLACY TYPES AND EXAMPLES:\n",
    "\"\"\"\n",
    "    \n",
    "    # Add examples for each label\n",
    "    for label in FINE_LABELS:\n",
    "        if label in examples and examples[label]:\n",
    "            prompt += f\"\\n{label}:\\n\"\n",
    "            for ex in examples[label][:max_examples_per_label]:\n",
    "                prompt += f'  - \"{ex}\"\\n'\n",
    "    \n",
    "    prompt += f\"\"\"\n",
    "Now extract ALL fallacy spans from this text:\n",
    "\n",
    "TEXT: \"{text}\"\n",
    "\n",
    "INSTRUCTIONS:\n",
    "1. Find ALL spans that contain fallacies (don't miss any!)\n",
    "2. A span can be a phrase, sentence, or multiple sentences\n",
    "3. Multiple spans can have the same label\n",
    "4. Return valid JSON with this format:\n",
    "{{\"spans\": [{{\"text\": \"exact text from input\", \"label\": \"Label-name\"}}]}}\n",
    "If no fallacies found: {{\"spans\": []}}\n",
    "Your response (JSON only):\"\"\"    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ec6d228",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_spans(text: str, examples: Dict[str, List[str]], model, tokenizer, device) -> List[Dict]:\n",
    "    prompt = create_few_shot_prompt(text, examples, max_examples_per_label=3)\n",
    "    response = generate(prompt, model, tokenizer, device, max_tokens=1024, temperature=0.1)\n",
    "    \n",
    "    print(f\"\\n  MODEL RESPONSE (first 500 chars):\")\n",
    "    print(f\"  {response[:500]}\")\n",
    "    print(f\"  ...\")\n",
    "    \n",
    "    spans = extract_spans_from_response(response)\n",
    "    print(f\"\\n  Extracted {len(spans)} spans:\")\n",
    "    for span in spans[:5]:  # Show first 5\n",
    "        print(f\"    - [{span['label']}] \\\"{span['text'][:60]}...\\\"\")\n",
    "    \n",
    "    return spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6ccb6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spans_to_bio_improved(text: str, tokens: List[str], spans: List[Dict]) -> List[str]:\n",
    "    token_labels = [set() for _ in tokens]\n",
    "    \n",
    "    # Build reconstructed text\n",
    "    reconstructed = \" \".join(tokens)\n",
    "    reconstructed_lower = reconstructed.lower()\n",
    "    \n",
    "    print(f\"\\n  Converting {len(spans)} spans to BIO tags...\")\n",
    "    \n",
    "    for span in spans:\n",
    "        span_text = span['text'].strip()\n",
    "        label = span['label']\n",
    "        matched = False\n",
    "        \n",
    "        # Strategy 1: Case-insensitive substring match in reconstructed text\n",
    "        span_text_lower = span_text.lower()\n",
    "        span_start = reconstructed_lower.find(span_text_lower)\n",
    "        \n",
    "        if span_start != -1:\n",
    "            # Count tokens before this position\n",
    "            prefix = reconstructed[:span_start]\n",
    "            tokens_before = len(prefix.split()) if prefix.strip() else 0\n",
    "            \n",
    "            # Count tokens in span\n",
    "            span_token_count = len(span_text.split())\n",
    "            \n",
    "            start_idx = tokens_before\n",
    "            end_idx = min(start_idx + span_token_count, len(tokens))\n",
    "            \n",
    "            if start_idx < len(tokens):\n",
    "                token_labels[start_idx].add(f\"B-{label}\")\n",
    "                for idx in range(start_idx + 1, end_idx):\n",
    "                    token_labels[idx].add(f\"I-{label}\")\n",
    "                matched = True\n",
    "                print(f\" Matched '{span_text[:40]}...' -> tokens[{start_idx}:{end_idx}]\")\n",
    "                continue\n",
    "        \n",
    "        # Strategy 2: Token-level fuzzy matching \n",
    "        if not matched:\n",
    "            span_tokens = span_text_lower.split()\n",
    "            if not span_tokens:\n",
    "                continue\n",
    "            \n",
    "            tokens_lower = [t.lower() for t in tokens]\n",
    "            best_match_start = -1\n",
    "            best_match_score = 0.0\n",
    "            \n",
    "            # Sliding window\n",
    "            for i in range(len(tokens_lower) - len(span_tokens) + 1):\n",
    "                window = tokens_lower[i:i + len(span_tokens)]\n",
    "                \n",
    "                # Calculate match score\n",
    "                matches = sum(1 for w, s in zip(window, span_tokens) if w == s or w in s or s in w)\n",
    "                score = matches / len(span_tokens)\n",
    "                \n",
    "                if score > best_match_score:\n",
    "                    best_match_score = score\n",
    "                    best_match_start = i\n",
    "            \n",
    "            # Apply if reasonable match \n",
    "            if best_match_start >= 0 and best_match_score >= 0.5:\n",
    "                end_idx = best_match_start + len(span_tokens)\n",
    "                token_labels[best_match_start].add(f\"B-{label}\")\n",
    "                for idx in range(best_match_start + 1, end_idx):\n",
    "                    token_labels[idx].add(f\"I-{label}\")\n",
    "                matched = True\n",
    "                print(f\" Fuzzy matched ({best_match_score:.2f}) '{span_text[:40]}...' -> tokens[{best_match_start}:{end_idx}]\")\n",
    "        \n",
    "        # Strategy 3: Check if span tokens appear anywhere in sequence\n",
    "        if not matched:\n",
    "            span_tokens = span_text_lower.split()\n",
    "            if len(span_tokens) >= 3:  # Only for longer spans\n",
    "                # Try to find first and last token\n",
    "                tokens_lower = [t.lower() for t in tokens]\n",
    "                first_token = span_tokens[0]\n",
    "                last_token = span_tokens[-1]\n",
    "                \n",
    "                # Find all occurrences of first token\n",
    "                for i, tok in enumerate(tokens_lower):\n",
    "                    if first_token in tok or tok in first_token:\n",
    "                        # Check if last token appears within reasonable distance\n",
    "                        for j in range(i + 1, min(i + len(span_tokens) + 3, len(tokens_lower))):\n",
    "                            if last_token in tokens_lower[j] or tokens_lower[j] in last_token:\n",
    "                                # Found a match!\n",
    "                                token_labels[i].add(f\"B-{label}\")\n",
    "                                for idx in range(i + 1, j + 1):\n",
    "                                    token_labels[idx].add(f\"I-{label}\")\n",
    "                                matched = True\n",
    "                                print(f\" Loose matched '{span_text[:40]}...' -> tokens[{i}:{j+1}]\")\n",
    "                                break\n",
    "                    if matched:\n",
    "                        break\n",
    "        \n",
    "        if not matched:\n",
    "            print(f\" FAILED to match: '{span_text[:50]}...'\")\n",
    "    \n",
    "    # Convert to BIO format with deduplication\n",
    "    bio_tags = []\n",
    "    for label_set in token_labels:\n",
    "        if not label_set:\n",
    "            bio_tags.append(\"O\")\n",
    "        else:\n",
    "            # Deduplicate: if both B- and I- exist for same label, keep only B-\n",
    "            deduplicated = set()\n",
    "            labels_seen = set()\n",
    "            \n",
    "            for tag in sorted(label_set):\n",
    "                if tag.startswith(\"B-\"):\n",
    "                    label = tag[2:]\n",
    "                    labels_seen.add(label)\n",
    "                    deduplicated.add(tag)\n",
    "                elif tag.startswith(\"I-\"):\n",
    "                    label = tag[2:]\n",
    "                    # Only add I- if we haven't seen B- for this label\n",
    "                    if label not in labels_seen:\n",
    "                        deduplicated.add(tag)\n",
    "            \n",
    "            bio_tags.append(\"|\".join(sorted(deduplicated)))\n",
    "    \n",
    "    # FIX: Clean up any I- tags that don't have a preceding B-\n",
    "    bio_tags = fix_bio_sequence(bio_tags)\n",
    "    \n",
    "    # VALIDATION: Check for malformed BIO sequences\n",
    "    validate_bio_tags(bio_tags, tokens)\n",
    "    \n",
    "    return bio_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddb2db4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_bio_sequence(bio_tags: List[str]) -> List[str]:\n",
    "    fixed_tags = []\n",
    "    \n",
    "    for idx, tag in enumerate(bio_tags):\n",
    "        if tag == \"O\":\n",
    "            fixed_tags.append(tag)\n",
    "            continue\n",
    "        \n",
    "        # Process each label in multi-label tags\n",
    "        labels_with_b = set()  # Labels that have B- in this token\n",
    "        labels_with_i = set()  # Labels that have I- in this token\n",
    "        \n",
    "        for single_tag in tag.split(\"|\"):\n",
    "            if single_tag.startswith(\"B-\"):\n",
    "                label = single_tag[2:]\n",
    "                labels_with_b.add(label)\n",
    "            elif single_tag.startswith(\"I-\"):\n",
    "                label = single_tag[2:]\n",
    "                labels_with_i.add(label)\n",
    "        \n",
    "        # Build the fixed tag list\n",
    "        final_labels = []\n",
    "        \n",
    "        # Add all B- tags (they're always valid)\n",
    "        for label in sorted(labels_with_b):\n",
    "            final_labels.append(f\"B-{label}\")\n",
    "        \n",
    "        # Process I- tags (only if no B- for same label and previous token has it)\n",
    "        for label in sorted(labels_with_i):\n",
    "            # Skip if we already have B- for this label\n",
    "            if label in labels_with_b:\n",
    "                continue\n",
    "            \n",
    "            # Check if previous token has this label\n",
    "            if idx > 0:\n",
    "                prev_tag = fixed_tags[idx - 1]\n",
    "                if f\"B-{label}\" in prev_tag or f\"I-{label}\" in prev_tag:\n",
    "                    # Valid continuation\n",
    "                    final_labels.append(f\"I-{label}\")\n",
    "                else:\n",
    "                    # Orphan I- becomes B-\n",
    "                    final_labels.append(f\"B-{label}\")\n",
    "            else:\n",
    "                # First token can't have I-, convert to B-\n",
    "                final_labels.append(f\"B-{label}\")\n",
    "        \n",
    "        if final_labels:\n",
    "            fixed_tags.append(\"|\".join(sorted(final_labels)))\n",
    "        else:\n",
    "            fixed_tags.append(\"O\")\n",
    "    \n",
    "    return fixed_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8469a6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_bio_tags(bio_tags: List[str], tokens: List[str]):\n",
    "    issues = []\n",
    "    active_spans = {}\n",
    "    span_count = 0\n",
    "    \n",
    "    for idx, tag in enumerate(bio_tags):\n",
    "        if tag == \"O\":\n",
    "            for label in list(active_spans.keys()):\n",
    "                span = active_spans[label]\n",
    "                expected_end = idx - 1\n",
    "                if span['start'] > expected_end:\n",
    "                    issues.append(f\"Invalid span for {label}: start={span['start']} > end={expected_end}\")\n",
    "                span_count += 1\n",
    "                del active_spans[label]\n",
    "            continue\n",
    "        current_labels = set()\n",
    "        for single_tag in tag.split(\"|\"):\n",
    "            if single_tag.startswith(\"B-\"):\n",
    "                label = single_tag[2:]\n",
    "                current_labels.add(label)\n",
    "                \n",
    "                # Close existing span if any\n",
    "                if label in active_spans:\n",
    "                    span = active_spans[label]\n",
    "                    expected_end = idx - 1\n",
    "                    if span['start'] > expected_end:\n",
    "                        issues.append(f\"Invalid span for {label}: start={span['start']} > end={expected_end}\")\n",
    "                    span_count += 1\n",
    "                \n",
    "                # Start new span\n",
    "                active_spans[label] = {'start': idx, 'tokens': [tokens[idx]]}\n",
    "                \n",
    "            elif single_tag.startswith(\"I-\"):\n",
    "                label = single_tag[2:]\n",
    "                current_labels.add(label)\n",
    "                \n",
    "                if label not in active_spans:\n",
    "                    issues.append(f\"I-{label} at position {idx} without preceding B-\")\n",
    "                else:\n",
    "                    active_spans[label]['tokens'].append(tokens[idx])\n",
    "        \n",
    "        # Close spans not in current labels\n",
    "        for label in list(active_spans.keys()):\n",
    "            if label not in current_labels:\n",
    "                span = active_spans[label]\n",
    "                expected_end = idx - 1\n",
    "                if span['start'] > expected_end:\n",
    "                    issues.append(f\"Invalid span for {label}: start={span['start']} > end={expected_end}\")\n",
    "                span_count += 1\n",
    "                del active_spans[label]\n",
    "    \n",
    "    # Close remaining spans\n",
    "    for label in active_spans:\n",
    "        span_count += 1\n",
    "    \n",
    "    if issues:\n",
    "        print(f\"    WARNING: BIO validation found {len(issues)} issues:\")\n",
    "        for issue in issues[:5]:\n",
    "            print(f\"    - {issue}\")\n",
    "    else:\n",
    "        print(f\"   BIO validation passed: {span_count} spans\")\n",
    "    \n",
    "    return bio_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c06cde45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_conll_predictions(posts: List[Dict], output_path: str, \n",
    "                           examples: Dict[str, List[str]], model, tokenizer, device):\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        for idx, post in enumerate(posts):\n",
    "            print(f\"\\nProcessing post {idx+1}/{len(posts)}: {post['post_id']}\")\n",
    "            \n",
    "            # Write metadata\n",
    "            f.write(f\"# post_id = {post['post_id']}\\n\")\n",
    "            f.write(f\"# post_date = {post['date']}\\n\")\n",
    "            f.write(f\"# post_topic_keywords = {post['topic']}\\n\")\n",
    "            f.write(f\"# post_text = {post['text']}\\n\")\n",
    "            \n",
    "            # Predict spans\n",
    "            predicted_spans = predict_spans(post['text'], examples, model, tokenizer, device)\n",
    "            \n",
    "            # Convert to BIO tags\n",
    "            bio_tags = spans_to_bio_improved(post['text'], post['tokens'], predicted_spans)\n",
    "            \n",
    "            # Ensure we have the right number of tokens\n",
    "            if len(bio_tags) != len(post['tokens']):\n",
    "                print(f\"   WARNING: Token count mismatch! tokens={len(post['tokens'])}, bio_tags={len(bio_tags)}\")\n",
    "                # Pad or truncate\n",
    "                if len(bio_tags) < len(post['tokens']):\n",
    "                    bio_tags.extend(['O'] * (len(post['tokens']) - len(bio_tags)))\n",
    "                else:\n",
    "                    bio_tags = bio_tags[:len(post['tokens'])]\n",
    "            for tok_idx, (token, bio_tag) in enumerate(zip(post['tokens'], bio_tags), start=1):\n",
    "                f.write(f\"{tok_idx}\\t{token}\\t{bio_tag}\\t{bio_tag}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "    \n",
    "    print(f\"\\nPredictions saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97bffa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(gold_path: str, pred_path: str):    \n",
    "    cmd = [\n",
    "        sys.executable,\n",
    "        \"eval.py\",\n",
    "        \"-S\", \"B\",\n",
    "        \"-G\", gold_path,\n",
    "        \"-P\", pred_path\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"RUNNING EVALUATION - SUBTASK B\")\n",
    "    print(\"=\"*60)\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    print(result.stdout)\n",
    "    if result.stderr:\n",
    "        print(\"STDERR:\", result.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f22a52d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing span extractor...\n",
      "Loading model on device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "179425398f2a4b209968ad9d936034b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parsing CoNLL file...\n",
      "Parsed 1152 posts from ../data/faina-v1.0_fadeit-shared-task/faina-v1.0_fadeit-shared-task/data/subtask-b/train-dev.conll\n",
      "\n",
      "Train: 921 posts\n",
      "Test: 231 posts\n",
      "\n",
      "Building few-shot examples...\n",
      "\n",
      "Built few-shot examples for 20 labels:\n",
      "  Ad-hominem: 3 examples\n",
      "  Appeal-to-authority: 3 examples\n",
      "  Appeal-to-emotion: 3 examples\n",
      "  Causal-oversimplification: 3 examples\n",
      "  Cherry-picking: 3 examples\n",
      "  Circular-reasoning: 3 examples\n",
      "  Doubt: 3 examples\n",
      "  Evading-the-burden-of-proof: 3 examples\n",
      "  False-analogy: 3 examples\n",
      "  False-dilemma: 3 examples\n",
      "  Flag-waving: 3 examples\n",
      "  Hasty-generalization: 3 examples\n",
      "  Loaded-language: 3 examples\n",
      "  Name-calling-or-labelling: 3 examples\n",
      "  Red-herring: 3 examples\n",
      "  Slippery-slope: 3 examples\n",
      "  Slogan: 3 examples\n",
      "  Strawman: 3 examples\n",
      "  Thought-terminating-cliches: 3 examples\n",
      "  Vagueness: 3 examples\n",
      "\n",
      "Generating predictions...\n",
      "\n",
      "Processing post 1/231: 353\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 2/231: 885\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 3/231: 1244\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Grazie [USER] per aver ricordato, durante lâ€™intervista a [USER], che in ambito politico importa  solo a [USER] della #questioneambientale. [USER] [USER] #giustiziaclimatica\", \"label\": \"Thought-terminating-cliches\"}}\n",
      "  ...\n",
      " JSON array parsing failed: Unterminated string starting at: line 1 column 11 (char 10)\n",
      " JSON object parsing failed: Expecting ',' delimiter: line 1 column 236 (char 235)\n",
      "  â†’ Trying line-by-line extraction...\n",
      " Extracted 1 spans line-by-line\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Thought-terminating-cliches] \"Grazie [USER] per aver ricordato, durante lâ€™intervista a [US...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Fuzzy matched (0.55) 'Grazie [USER] per aver ricordato, durant...' -> tokens[3:25]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 4/231: 451\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Di quando con gli idranti si sgomberavano i rifugiati e nessuno alzava un dito #piazzaindipendenza #roma [URL]\", \"label\": \"Red-herring\"}}]\n",
      "  ...\n",
      " JSON array parsing failed: Expecting ',' delimiter: line 1 column 148 (char 147)\n",
      " JSON object parsing failed: Expecting ',' delimiter: line 1 column 158 (char 157)\n",
      "  â†’ Trying line-by-line extraction...\n",
      " Extracted 1 spans line-by-line\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Red-herring] \"Di quando con gli idranti si sgomberavano i rifugiati e ness...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Fuzzy matched (0.88) 'Di quando con gli idranti si sgomberavan...' -> tokens[0:17]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 5/231: 1029\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 6/231: 257\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 7/231: 1077\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"ma come fa un medico ad essere contrario a cure e vaccini?\", \"label\": \"Thought-terminating-cliches\"}, {\"text\": \"Ed Ã¨ pure indagato per procurato allarme.\", \"label\": \"Appeal-to-authority\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 2 spans:\n",
      "    - [Thought-terminating-cliches] \"ma come fa un medico ad essere contrario a cure e vaccini?...\"\n",
      "    - [Appeal-to-authority] \"Ed Ã¨ pure indagato per procurato allarme....\"\n",
      "\n",
      "  Converting 2 spans to BIO tags...\n",
      " Fuzzy matched (1.00) 'ma come fa un medico ad essere contrario...' -> tokens[40:52]\n",
      " Fuzzy matched (1.00) 'Ed Ã¨ pure indagato per procurato allarme...' -> tokens[28:35]\n",
      "   BIO validation passed: 2 spans\n",
      "\n",
      "Processing post 8/231: 1062\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 9/231: 761\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"I cittadini pretendono risposte da un governo che ancora non ha pagato #cassaintegrazione a 2,6 milioni di italiani nÃ© #bonus600euro a 1 milione di lavoratori autonomi. E intanto pensa a sanatorie immigrati e a moltiplicare poltrone [URL]\", \"label\": \"Strawman\"}}]\n",
      "  ...\n",
      " JSON array parsing failed: Expecting ',' delimiter: line 1 column 273 (char 272)\n",
      " JSON object parsing failed: Expecting ',' delimiter: line 1 column 283 (char 282)\n",
      "  â†’ Trying line-by-line extraction...\n",
      " Extracted 1 spans line-by-line\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Strawman] \"I cittadini pretendono risposte da un governo che ancora non...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Loose matched 'I cittadini pretendono risposte da un go...' -> tokens[9:49]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 10/231: 213\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 11/231: 1331\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Scusate, governo dei fasci e delle corporazioni. Quando la fate una legge che vieti ai giornali di uscire il lunedÃ¬, cosÃ¬ finalmente noi poveri giornalisti potremo passare la domenica in famiglia? (Ah, e gli ospedali aperti la domenica, siamo matti)?\", \"label\": \"Thought-terminating-cliches\"}}\n",
      "  ...\n",
      " JSON object parsing failed: Expecting ',' delimiter: line 1 column 314 (char 313)\n",
      "  â†’ Trying line-by-line extraction...\n",
      " Extracted 1 spans line-by-line\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Thought-terminating-cliches] \"Scusate, governo dei fasci e delle corporazioni. Quando la f...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Loose matched 'Scusate, governo dei fasci e delle corpo...' -> tokens[0:35]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 12/231: 1365\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 13/231: 385\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 14/231: 745\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 15/231: 73\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"La sinistra non riesce ancora a distinguere tra profughi ed immigrati irregolari , noi non siamo contro di loro ma contro chi li sfrutta !\", \"label\": \"None of the above (no specific fallacy type applies)\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 16/231: 219\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 17/231: 144\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 18/231: 1221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 19/231: 379\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Se queste cose non si fanno Ã¨ una scelta dei parlamentari, prescindendo dal governo\", \"label\": \"Flag-waving\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Flag-waving] \"Se queste cose non si fanno Ã¨ una scelta dei parlamentari, p...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Fuzzy matched (0.79) 'Se queste cose non si fanno Ã¨ una scelta...' -> tokens[29:43]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 20/231: 1424\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Francamente sentire qualcuno sostenere che i cadaveri trovati ad Auschwitz furono dovuti a una epidemia di tifo  e che l'Olocausto non Ã¨ mai esistito, fa rabbrividire, non mi consola capire che Ã¨ un pazzo furioso, penso a Liliana Segre e mi sento male. MALE.\", \"label\": \"Strawman\"}}\n",
      "  ...\n",
      " JSON object parsing failed: Expecting ',' delimiter: line 1 column 303 (char 302)\n",
      "  â†’ Trying line-by-line extraction...\n",
      " Extracted 1 spans line-by-line\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Strawman] \"Francamente sentire qualcuno sostenere che i cadaveri trovat...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Fuzzy matched (0.55) 'Francamente sentire qualcuno sostenere c...' -> tokens[0:44]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 21/231: 402\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Rimettete Salvini al Viminale, Ã¨ lâ€™unico capace di governare lâ€™arrivo dei migranti.\", \"label\": \"None of the listed fallacies apply to this text.\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 22/231: 1146\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Ah, ecco... ðŸ˜¬ Poi il problema sono perÃ² i migranti, vero [USER]??? ðŸ¤  Enzo Misiano: il consigliere di Fratelli dâ€™Italia arrestato per â€˜ndrangheta [URL]\", \"label\": \"Name-calling-or-labelling\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Name-calling-or-labelling] \"Ah, ecco... ðŸ˜¬ Poi il problema sono perÃ² i migranti, vero [US...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Loose matched 'Ah, ecco... ðŸ˜¬ Poi il problema sono perÃ² ...' -> tokens[12:33]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 23/231: 1316\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 24/231: 48\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 25/231: 43\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Lâ€™Italia Ã¨ quel paese dove la #solidarietÃ  verso i #rifugiati #ucraini ha evidenziato tutto il #razzismo di parte degli #italiani verso i #rifugiati di altri paesi. Da italiano provo tanta vergognaâ€¦e voi ?!\", \"label\": \"Thought-terminating-cliches\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Thought-terminating-cliches] \"Lâ€™Italia Ã¨ quel paese dove la #solidarietÃ  verso i #rifugiat...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Loose matched 'Lâ€™Italia Ã¨ quel paese dove la #solidarie...' -> tokens[10:43]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 26/231: 1033\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 27/231: 1245\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 28/231: 779\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 29/231: 953\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 30/231: 268\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 31/231: 1431\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 32/231: 648\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 33/231: 1\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Ovvero come la Serbia, che protesta per #Djokovic, ha trattato per mesi le persone su #rottabalcanica [URL]\", \"label\": \"Cherry-picking\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Cherry-picking] \"Ovvero come la Serbia, che protesta per #Djokovic, ha tratta...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Fuzzy matched (0.53) 'Ovvero come la Serbia, che protesta per ...' -> tokens[35:52]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 34/231: 1235\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 35/231: 46\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"PerÃ² se provava a fuggire in Italia l'avrebbe considerata una immigrata che invade il nostro paese da bloccare non essendo ariana come gli ucraini #ipocrisia\", \"label\": \"Slippery-slope\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Slippery-slope] \"PerÃ² se provava a fuggire in Italia l'avrebbe considerata un...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Fuzzy matched (0.76) 'PerÃ² se provava a fuggire in Italia l'av...' -> tokens[15:40]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 36/231: 1049\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 37/231: 1108\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"La bambina viene circondata dagli immigrati, e uno di loro dice â€œvuoi il mio uccello nella tua xxxx?â€\", \"label\": \"Slippery-slope\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Slippery-slope] \"La bambina viene circondata dagli immigrati, e uno di loro d...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Loose matched 'La bambina viene circondata dagli immigr...' -> tokens[12:32]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 38/231: 798\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"proprio non li sopporto piÃ¹ questi migranti in discoteca senza mascherina e pieni di #Covid_19. Prima gli italiani in discoteca!!!! Poverini si devono svagare dopo il lockdown...Per i selfies ricevo 24/7  anche #Ferragosto bacioni\", \"label\": \"Slippery-slope\"}}\n",
      "  ...\n",
      " JSON object parsing failed: Expecting ',' delimiter: line 1 column 281 (char 280)\n",
      "  â†’ Trying line-by-line extraction...\n",
      " Extracted 1 spans line-by-line\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Slippery-slope] \"proprio non li sopporto piÃ¹ questi migranti in discoteca sen...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Fuzzy matched (0.50) 'proprio non li sopporto piÃ¹ questi migra...' -> tokens[0:34]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 39/231: 1254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Questo Ã¨ il Modello #Milano caro al Sindaco [USER]? Evidentemente la Giunta adesso si focalizza solo sui rincari #Atm e il resto puÃ² aspettare...\", \"label\": \"Red-herring\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Red-herring] \"Questo Ã¨ il Modello #Milano caro al Sindaco [USER]? Evidente...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Loose matched 'Questo Ã¨ il Modello #Milano caro al Sind...' -> tokens[18:41]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 40/231: 808\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 41/231: 373\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Poi se parliamo di propaganda vs realtÃ , allora sÃ¬, il problema Ã¨ enorme  #GovernoDraghi\", \"label\": \"Vagueness\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Vagueness] \"Poi se parliamo di propaganda vs realtÃ , allora sÃ¬, il probl...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Fuzzy matched (0.50) 'Poi se parliamo di propaganda vs realtÃ ,...' -> tokens[31:45]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 42/231: 237\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Ma poi l'Europa ha deliberato ogni quanto bisogna cambiare le mutande per il cambiamento climatico e tutto il resto ?\", \"label\": \"Vagueness\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Vagueness] \"Ma poi l'Europa ha deliberato ogni quanto bisogna cambiare l...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Fuzzy matched (0.90) 'Ma poi l'Europa ha deliberato ogni quant...' -> tokens[1:21]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 43/231: 640\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 44/231: 115\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Lo sfruttamento dei #migranti Ã¨ lâ€™ultimo livello di una montagna di schiavismo che opprime la societÃ  .. stralcio del mio intervento a #Bergamo in solidarietÃ  coi #lavoratori caricati dalla polizia SCHIAVI MAI [URL]\", \"label\": \"Strawman\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Strawman] \"Lo sfruttamento dei #migranti Ã¨ lâ€™ultimo livello di una mont...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Fuzzy matched (0.55) 'Lo sfruttamento dei #migranti Ã¨ lâ€™ultimo...' -> tokens[2:35]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 45/231: 1406\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Se ho ischemie alla testa da tenere monitorate non puoi dirmi che hai posto per la risonanza a GIUGNO 2020. Per un ecografia ad un nodulo alla tiroide non puoi dirmi febbraio 2020. Ma lo fai.. ðŸ˜”ðŸ˜¡\", \"label\": \"Cherry-picking\"}}]\n",
      "  ...\n",
      " JSON array parsing failed: Expecting ',' delimiter: line 1 column 236 (char 235)\n",
      " JSON object parsing failed: Expecting ',' delimiter: line 1 column 246 (char 245)\n",
      "  â†’ Trying line-by-line extraction...\n",
      " Extracted 1 spans line-by-line\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Cherry-picking] \"Se ho ischemie alla testa da tenere monitorate non puoi dirm...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Fuzzy matched (0.54) 'Se ho ischemie alla testa da tenere moni...' -> tokens[16:53]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 46/231: 228\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Concetto non chiarissimo in Italia :l'evasione fiscale scatta con la non emissioni dello scontrino fiscale il pagamento in contanti o con metodi tracciabili non fa alcuna differenza.\", \"label\": \"Vagueness\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Vagueness] \"Concetto non chiarissimo in Italia :l'evasione fiscale scatt...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Fuzzy matched (0.81) 'Concetto non chiarissimo in Italia :l'ev...' -> tokens[2:29]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 47/231: 1246\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 48/231: 119\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 49/231: 1183\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Pensare che un diversamente abile sia economicamente meno considerato degli immigrati in un Paese Ã¨ davvero uno SCHIFO.\", \"label\": \"Name-calling-or-labelling\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Name-calling-or-labelling] \"Pensare che un diversamente abile sia economicamente meno co...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Fuzzy matched (1.00) 'Pensare che un diversamente abile sia ec...' -> tokens[16:34]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 50/231: 460\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 51/231: 1142\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Dopo #primairussi #primaimigranti #primaleong #primaicanielepapere potrebbe trovare qualche minuto per occuparsi di #primaledonne e la loro sicurezza?\", \"label\": \"Hasty-generalization\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Hasty-generalization] \"Dopo #primairussi #primaimigranti #primaleong #primaicaniele...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Fuzzy matched (0.71) 'Dopo #primairussi #primaimigranti #prima...' -> tokens[26:43]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 52/231: 456\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"continuano a negare i tamponi gratis ai lavoratori  per lavorare...\", \"label\": \"Evading-the-burden-of-proof\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Evading-the-burden-of-proof] \"continuano a negare i tamponi gratis ai lavoratori  per lavo...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Fuzzy matched (1.00) 'continuano a negare i tamponi gratis ai ...' -> tokens[15:25]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 53/231: 1010\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Ãˆ inammissibile che a gestire la piÃ¹ grande crisi sanitaria ed economica della storia della nostra Repubblica sia un illustre sconosciuto che non gode di alcun tipo di legittimazione da parte del popolo sovrano, che non lo ha mai votato in nessun consesso.\", \"label\": \"Strawman\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Strawman] \"Ãˆ inammissibile che a gestire la piÃ¹ grande crisi sanitaria ...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Fuzzy matched (0.79) 'Ãˆ inammissibile che a gestire la piÃ¹ gra...' -> tokens[0:43]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 54/231: 269\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 55/231: 265\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 56/231: 632\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 57/231: 88\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Su immigrazione #Calenda stessa posizione e stessa retorica della destra #mezzorainpiu\", \"label\": \"Thought-terminating-cliches\"}}]\n",
      "  ...\n",
      " JSON array parsing failed: Expecting ',' delimiter: line 1 column 140 (char 139)\n",
      " JSON object parsing failed: Expecting ',' delimiter: line 1 column 150 (char 149)\n",
      "  â†’ Trying line-by-line extraction...\n",
      " Extracted 1 spans line-by-line\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Thought-terminating-cliches] \"Su immigrazione #Calenda stessa posizione e stessa retorica ...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Fuzzy matched (0.82) 'Su immigrazione #Calenda stessa posizion...' -> tokens[1:12]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 58/231: 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 59/231: 846\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 60/231: 1096\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Una ragazza  racconta al Commissario di essere stata violentata ma Montalbano arriva a dire che sono stati gli scafisti perchÃ¨ i migranti non fanno queste cose!\", \"label\": \"Strawman\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Strawman] \"Una ragazza  racconta al Commissario di essere stata violent...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Fuzzy matched (1.00) 'Una ragazza  racconta al Commissario di ...' -> tokens[9:35]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 61/231: 296\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 62/231: 978\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 63/231: 170\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \".[USER] oltre la parola Transizione Ecologica come vorreste chiudere il ciclo dei rifiuti a Roma? In 5 anni al Governo della Capitale l'unica transizione che avete fatto Ã¨ quella ai rifiuti per strada. #SiTermovalorizzatore [URL]\", \"label\": \"Red-herring\"}}]\n",
      "  ...\n",
      " JSON array parsing failed: Expecting ',' delimiter: line 1 column 267 (char 266)\n",
      " JSON object parsing failed: Expecting ',' delimiter: line 1 column 277 (char 276)\n",
      "  â†’ Trying line-by-line extraction...\n",
      " Extracted 1 spans line-by-line\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Red-herring] \".[USER] oltre la parola Transizione Ecologica come vorreste ...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Loose matched '.[USER] oltre la parola Transizione Ecol...' -> tokens[36:40]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 64/231: 1166\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Castelvolturno, rivolta degli italiani contro immigrati. (video) [URL]\", \"label\": \"Red-herring\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Red-herring] \"Castelvolturno, rivolta degli italiani contro immigrati. (vi...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Fuzzy matched (0.75) 'Castelvolturno, rivolta degli italiani c...' -> tokens[1:9]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 65/231: 727\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"A voi uno stato che per prevenire il #coronavirus blocca, giustamente, per controlli #navidacrociera a #Civitavecchia e fa sbarcare centinaia di immigrati dalle navi delle #ONG e dai #barchini\", \"label\": \"Red-herring\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Red-herring] \"A voi uno stato che per prevenire il #coronavirus blocca, gi...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Loose matched 'A voi uno stato che per prevenire il #co...' -> tokens[0:9]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 66/231: 162\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 67/231: 436\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 68/231: 1382\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 69/231: 873\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 70/231: 244\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 71/231: 991\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 72/231: 1439\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Nella riforma sanitaria in corso in FVG, laddove il concetto di famiglia viene rappresentato come assolutamente centrale, il #PD ha presentato una serie di emendamenti per RIMUOVERE LA PAROLA FAMIGLIA e sostituirla con la dicitura RETE FORMALE E INFORMALE DELLA PERSONA.  RIDICOLI [URL]\", \"label\": \"Strawman\"}}\n",
      "  ...\n",
      " JSON array parsing failed: Unterminated string starting at: line 1 column 11 (char 10)\n",
      " JSON object parsing failed: Expecting ',' delimiter: line 1 column 331 (char 330)\n",
      "  â†’ Trying line-by-line extraction...\n",
      " Extracted 1 spans line-by-line\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Strawman] \"Nella riforma sanitaria in corso in FVG, laddove il concetto...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Fuzzy matched (0.53) 'Nella riforma sanitaria in corso in FVG,...' -> tokens[3:46]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 73/231: 636\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 74/231: 1258\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"#COP26 su clima si svolgerÃ  \\\"congiuntamente\\\" in Italia e Gran Bretagna... in effetti dopo aver bocciato mozione su #EmergenzaClimatica farla solo in Italia era RIDICOLO!  #negazionisticlimatici #congiuntamentefregati [URL]\", \"label\": \"Slippery-slope\"}}]}\n",
      "\n",
      "Explanation:\n",
      "The text contains a slippery slope fallacy. The statement suggests that after rejecting a motion on climate emergency, it would be ridiculous to hold the conference only in Italy. This implies a series of inc\n",
      "  ...\n",
      " JSON array parsing failed: Expecting ',' delimiter: line 1 column 265 (char 264)\n",
      " JSON object parsing failed: Expecting ',' delimiter: line 1 column 275 (char 274)\n",
      "  â†’ Trying line-by-line extraction...\n",
      " Extracted 1 spans line-by-line\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Slippery-slope] \"#COP26 su clima si svolgerÃ  \\...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Fuzzy matched (0.83) '#COP26 su clima si svolgerÃ  \\...' -> tokens[1:7]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 75/231: 726\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Che poi Ã¨ la stessa logica di quelli che i migranti non scappano dalle guerre o dalla fame perchÃ© hanno uno smartphone o sono muscolosi.\", \"label\": \"False analogy\"}, {\"text\": \"Quindi secondo la signora che ha portato Salvini a Bologna il ragazzo spaccia perchÃ© â€œÃ¨ sempre vestito bene e firmatoâ€. \", \"label\": \"False analogy\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 2 spans:\n",
      "    - [False-analogy] \"Che poi Ã¨ la stessa logica di quelli che i migranti non scap...\"\n",
      "    - [False-analogy] \"Quindi secondo la signora che ha portato Salvini a Bologna i...\"\n",
      "\n",
      "  Converting 2 spans to BIO tags...\n",
      " Fuzzy matched (1.00) 'Che poi Ã¨ la stessa logica di quelli che...' -> tokens[23:48]\n",
      " Fuzzy matched (0.80) 'Quindi secondo la signora che ha portato...' -> tokens[0:20]\n",
      "   BIO validation passed: 2 spans\n",
      "\n",
      "Processing post 76/231: 882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 77/231: 963\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 78/231: 147\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 79/231: 924\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Che si fa? Si ðŸ˜‚ðŸ˜‚ðŸ˜‚ o si ðŸ˜¥ðŸ˜¥ðŸ˜¥\", \"label\": \"Cherry-picking\"}, {\"text\": \"Che si fa? Si ðŸ˜‚ðŸ˜‚ðŸ˜‚ o si ðŸ˜¥ðŸ˜¥ðŸ˜¥\", \"label\": \"Cherry-picking\"}, {\"text\": \"Comunque #greenwashing [URL]\", \"label\": \"False-dilemma\"}}]}\n",
      "  ...\n",
      " JSON array parsing failed: Expecting ',' delimiter: line 1 column 202 (char 201)\n",
      " JSON object parsing failed: Expecting ',' delimiter: line 1 column 212 (char 211)\n",
      "  â†’ Trying line-by-line extraction...\n",
      " Extracted 1 spans line-by-line\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Cherry-picking] \"Che si fa? Si ðŸ˜‚ðŸ˜‚ðŸ˜‚ o si ðŸ˜¥ðŸ˜¥ðŸ˜¥...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Fuzzy matched (0.62) 'Che si fa? Si ðŸ˜‚ðŸ˜‚ðŸ˜‚ o si ðŸ˜¥ðŸ˜¥ðŸ˜¥...' -> tokens[46:54]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 80/231: 563\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 81/231: 1222\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Certo che dietro la comparsa  miracolosa di Greta, l'emergenza climatica, gli scioperi studenteschi sul riscaldamento globale,  il monito di Mattarella sulla catastrofe ambientalista prossima ventura, c'Ã¨ una regia raffinatissima.\", \"label\": \"Vagueness\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Vagueness] \"Certo che dietro la comparsa  miracolosa di Greta, l'emergen...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " FAILED to match: 'Certo che dietro la comparsa  miracolosa di Greta,...'\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 82/231: 13\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Ma saranno loro eh [URL]\", \"label\": \"Cherry-picking\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Cherry-picking] \"Ma saranno loro eh [URL]...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Matched 'Ma saranno loro eh [URL]...' -> tokens[43:48]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 83/231: 907\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 84/231: 1129\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 85/231: 491\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 86/231: 464\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"ChissÃ  se nell'autorizzare al consumo umano la \\\"locusta migratoria\\\" la Commissione Europea abbia voluto prenderci in giro...  Capite che siamo in mano a persone pericolose o no?\", \"label\": \"Strawman\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Strawman] \"ChissÃ  se nell'autorizzare al consumo umano la \"locusta migr...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Loose matched 'ChissÃ  se nell'autorizzare al consumo um...' -> tokens[0:30]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 87/231: 468\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 88/231: 1154\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"PerchÃ© invece del cervello usa l'intestino per pensare e produce odio\", \"label\": \"Thought-terminating-cliches\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Thought-terminating-cliches] \"PerchÃ© invece del cervello usa l'intestino per pensare e pro...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Fuzzy matched (0.64) 'PerchÃ© invece del cervello usa l'intesti...' -> tokens[39:50]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 89/231: 592\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 90/231: 818\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Queste sono le frasi che da mesi ripetono Salvini Meloni. Avete mai sentito una loro proposta concreta in economia, per la sanitÃ  ecc ?\", \"label\": \"Vagueness\"}, {\"text\": \"Solo propaganda e urla, fine\", \"label\": \"Flag-waving\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 2 spans:\n",
      "    - [Vagueness] \"Queste sono le frasi che da mesi ripetono Salvini Meloni. Av...\"\n",
      "    - [Flag-waving] \"Solo propaganda e urla, fine...\"\n",
      "\n",
      "  Converting 2 spans to BIO tags...\n",
      " Loose matched 'Queste sono le frasi che da mesi ripeton...' -> tokens[19:45]\n",
      " Fuzzy matched (0.80) 'Solo propaganda e urla, fine...' -> tokens[47:52]\n",
      "   BIO validation passed: 2 spans\n",
      "\n",
      "Processing post 91/231: 651\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 92/231: 1131\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"finirÃ  come con \\\"migrante risorsa ci paga le pensioni\\\"\", \"label\": \"False-dilemma\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [False-dilemma] \"finirÃ  come con \"migrante risorsa ci paga le pensioni\"...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Fuzzy matched (0.67) 'finirÃ  come con \"migrante risorsa ci pag...' -> tokens[44:53]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 93/231: 77\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 94/231: 749\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Stanno entrando un mare di immigrati e nessuno ne parla. Si sommano i problemi, dove andremo a finire?\", \"label\": \"Vagueness\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Vagueness] \"Stanno entrando un mare di immigrati e nessuno ne parla. Si ...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Fuzzy matched (0.61) 'Stanno entrando un mare di immigrati e n...' -> tokens[0:18]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 95/231: 333\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Il vaccino Ã¨ stato testato per prevenire la malattia grave.  Test successivi ne hanno dimostrato lâ€™efficacia contro lâ€™infezione. Da qui la scelta politica del Greenpass. Con le varianti la capacitÃ  di combattere la trasmissione Ã¨ venuta gradualmente meno.  Il resto Ã¨â€¦ truffa.\", \"label\": \"Vagueness\"}}\n",
      "  ...\n",
      " JSON object parsing failed: Expecting ',' delimiter: line 1 column 322 (char 321)\n",
      "  â†’ Trying line-by-line extraction...\n",
      " Extracted 1 spans line-by-line\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Vagueness] \"Il vaccino Ã¨ stato testato per prevenire la malattia grave. ...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Loose matched 'Il vaccino Ã¨ stato testato per prevenire...' -> tokens[0:11]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 96/231: 781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"La Polizia blocca un ragazzino ma non #Salvini quando insulta i migranti o citofona o altro.\", \"label\": \"Thought-terminating-cliches\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Thought-terminating-cliches] \"La Polizia blocca un ragazzino ma non #Salvini quando insult...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Fuzzy matched (0.81) 'La Polizia blocca un ragazzino ma non #S...' -> tokens[33:49]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 97/231: 618\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 98/231: 821\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"ChissÃ !\", \"label\": \"Slogan\"}, {\"text\": \"nel frattempo il razzista, sessista e omofobo Trump pare giÃ  un brutto ricordo #KamalaHarris\", \"label\": \"Strawman\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 2 spans:\n",
      "    - [Slogan] \"ChissÃ !...\"\n",
      "    - [Strawman] \"nel frattempo il razzista, sessista e omofobo Trump pare giÃ ...\"\n",
      "\n",
      "  Converting 2 spans to BIO tags...\n",
      " Fuzzy matched (1.00) 'ChissÃ !...' -> tokens[25:26]\n",
      " Fuzzy matched (0.79) 'nel frattempo il razzista, sessista e om...' -> tokens[28:42]\n",
      "   BIO validation passed: 2 spans\n",
      "\n",
      "Processing post 99/231: 311\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Non possono esser detta la nazionalitÃ  di uno stupratore altrimenti i razzisti...\", \"label\": \"Strawman\"}, {\"text\": \"Questa Ã¨ oggi l'informazione.\", \"label\": \"Vagueness\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 2 spans:\n",
      "    - [Strawman] \"Non possono esser detta la nazionalitÃ  di uno stupratore alt...\"\n",
      "    - [Vagueness] \"Questa Ã¨ oggi l'informazione....\"\n",
      "\n",
      "  Converting 2 spans to BIO tags...\n",
      " Fuzzy matched (0.92) 'Non possono esser detta la nazionalitÃ  d...' -> tokens[29:41]\n",
      " Fuzzy matched (1.00) 'Questa Ã¨ oggi l'informazione....' -> tokens[42:46]\n",
      "   BIO validation passed: 2 spans\n",
      "\n",
      "Processing post 100/231: 44\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 101/231: 178\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 102/231: 1185\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Popolo ha colpa di tutta questa merda . Popolo di analfabeti funzionali.\", \"label\": \"Thought-terminating-cliches\"}, {\"text\": \"CosÃ¬ si vince facile.\", \"label\": \"Slogan\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 2 spans:\n",
      "    - [Thought-terminating-cliches] \"Popolo ha colpa di tutta questa merda . Popolo di analfabeti...\"\n",
      "    - [Slogan] \"CosÃ¬ si vince facile....\"\n",
      "\n",
      "  Converting 2 spans to BIO tags...\n",
      " Fuzzy matched (1.00) 'Popolo ha colpa di tutta questa merda . ...' -> tokens[24:36]\n",
      " Fuzzy matched (1.00) 'CosÃ¬ si vince facile....' -> tokens[53:57]\n",
      "   BIO validation passed: 2 spans\n",
      "\n",
      "Processing post 103/231: 533\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 104/231: 819\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 105/231: 669\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 106/231: 1414\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 107/231: 70\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Non Ã¨ possibile istaurare procedure di sbarco e soccorso in un altra sede ?\", \"label\": \"Hasty-generalization\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Hasty-generalization] \"Non Ã¨ possibile istaurare procedure di sbarco e soccorso in ...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Matched 'Non Ã¨ possibile istaurare procedure di s...' -> tokens[33:47]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 108/231: 956\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 109/231: 245\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 110/231: 1341\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 111/231: 736\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 112/231: 221\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Ma quanto fa schifo questa transizione ecologica Imposta dall'UnioneEuropea?\", \"label\": \"Slogan\"}, {\"text\": \"Si dia da fare.\", \"label\": \"Slogan\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 2 spans:\n",
      "    - [Slogan] \"Ma quanto fa schifo questa transizione ecologica Imposta dal...\"\n",
      "    - [Slogan] \"Si dia da fare....\"\n",
      "\n",
      "  Converting 2 spans to BIO tags...\n",
      " Fuzzy matched (1.00) 'Ma quanto fa schifo questa transizione e...' -> tokens[21:30]\n",
      " Fuzzy matched (1.00) 'Si dia da fare....' -> tokens[42:46]\n",
      "   BIO validation passed: 2 spans\n",
      "\n",
      "Processing post 113/231: 643\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 114/231: 1408\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Boh. Cose strane.\", \"label\": \"Hasty-generalization\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Hasty-generalization] \"Boh. Cose strane....\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Fuzzy matched (1.00) 'Boh. Cose strane....' -> tokens[41:44]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 115/231: 1006\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 116/231: 1289\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 117/231: 917\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 118/231: 1212\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Sperate che noi giovani faremmo qualcosa per fermare il riscaldamento globale, ma purtroppo non faremo in tempo a raggiungere i posti di potere per farlo Immensa e inarrestabile [USER] #PrimaDelDiluvio #FridaysForFuture #VerdeDÃ¬ ðŸ’š [USER]\", \"label\": \"Strawman\"}}\n",
      "  ...\n",
      " JSON array parsing failed: Unterminated string starting at: line 1 column 11 (char 10)\n",
      " JSON object parsing failed: Expecting ',' delimiter: line 1 column 282 (char 281)\n",
      "  â†’ Trying line-by-line extraction...\n",
      " Extracted 1 spans line-by-line\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Strawman] \"Sperate che noi giovani faremmo qualcosa per fermare il risc...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Fuzzy matched (0.62) 'Sperate che noi giovani faremmo qualcosa...' -> tokens[1:35]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 119/231: 549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Potete elettrificare tutte le auto del mondo, ma se non convincete la gente che gli spostamenti di breve raggio vanno fatti a piedi o in bici, col cavolo che ridurremo le emissioni di CO2 in modo sostanziale.\", \"label\": \"Causal-oversimplification\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Causal-oversimplification] \"Potete elettrificare tutte le auto del mondo, ma se non conv...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Fuzzy matched (0.54) 'Potete elettrificare tutte le auto del m...' -> tokens[1:38]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 120/231: 1042\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 121/231: 6\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 122/231: 342\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 123/231: 1379\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 124/231: 231\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Di commenti cosÃ¬ ce ne sono migliaia in rete, in un'alluvione di ignoranza, machismo, idiozia che fa rivoltare le viscere.\", \"label\": \"Appeal-to-emotion\"}, {\"text\": \"fate schifo, siete usurpatori di ossigeno\", \"label\": \"Name-calling-or-labelling\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 2 spans:\n",
      "    - [Appeal-to-emotion] \"Di commenti cosÃ¬ ce ne sono migliaia in rete, in un'alluvion...\"\n",
      "    - [Name-calling-or-labelling] \"fate schifo, siete usurpatori di ossigeno...\"\n",
      "\n",
      "  Converting 2 spans to BIO tags...\n",
      " Loose matched 'Di commenti cosÃ¬ ce ne sono migliaia in ...' -> tokens[5:12]\n",
      " Fuzzy matched (0.83) 'fate schifo, siete usurpatori di ossigen...' -> tokens[38:44]\n",
      "   BIO validation passed: 2 spans\n",
      "\n",
      "Processing post 125/231: 602\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"il 73% degli italiani pensa che #Renzi stia perseguendo solo â€œâ€i suoi interessi personali.  E questo, in piena pandemia, fa ancora piÃ¹ schifo.\", \"label\": \"Appeal-to-emotion\"}, {\"text\": \"E questo, in piena pandemia, fa ancora piÃ¹ schifo.\", \"label\": \"Appeal-to-emotion\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 2 spans:\n",
      "    - [Appeal-to-emotion] \"il 73% degli italiani pensa che #Renzi stia perseguendo solo...\"\n",
      "    - [Appeal-to-emotion] \"E questo, in piena pandemia, fa ancora piÃ¹ schifo....\"\n",
      "\n",
      "  Converting 2 spans to BIO tags...\n",
      " Loose matched 'il 73% degli italiani pensa che #Renzi s...' -> tokens[3:18]\n",
      " Fuzzy matched (0.56) 'E questo, in piena pandemia, fa ancora p...' -> tokens[23:32]\n",
      "   BIO validation passed: 2 spans\n",
      "\n",
      "Processing post 126/231: 131\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 127/231: 797\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Ãˆ il numero dei rifugiati in #Libia di cui mi sto occupando ora. Tutti abbandonati in Libia, nei lager, da almeno 3 anni, salvo i bimbi che ci sono nati. Malati, affamati. A voi che dissertate sui #dirittiumani, ricordo che questi umani hanno bisogno di aiuto.\", \"label\": \"Vagueness\"}}]\n",
      "  ...\n",
      " JSON array parsing failed: Expecting ',' delimiter: line 1 column 296 (char 295)\n",
      " JSON object parsing failed: Expecting ',' delimiter: line 1 column 306 (char 305)\n",
      "  â†’ Trying line-by-line extraction...\n",
      " Extracted 1 spans line-by-line\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Vagueness] \"Ãˆ il numero dei rifugiati in #Libia di cui mi sto occupando ...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Loose matched 'Ãˆ il numero dei rifugiati in #Libia di c...' -> tokens[2:17]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 128/231: 843\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 129/231: 865\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 130/231: 894\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 131/231: 376\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"[URL]\", \"label\": \"Cherry-picking\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Cherry-picking] \"[URL]...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Matched '[URL]...' -> tokens[31:32]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 132/231: 1159\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 133/231: 1053\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Intanto nei mesi della pandemia i dl Salvini hanno continuato a fare parecchi danni (accoglienza).\", \"label\": \"Cherry-picking\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Cherry-picking] \"Intanto nei mesi della pandemia i dl Salvini hanno continuat...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Fuzzy matched (1.00) 'Intanto nei mesi della pandemia i dl Sal...' -> tokens[28:43]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 134/231: 86\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 135/231: 800\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Chi attacca [USER] su questione immigrazione/lavoratori africani (video da [USER]) ha un problema: quello di non capire una beata minchia.\", \"label\": \"Thought-terminating-cliches\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Thought-terminating-cliches] \"Chi attacca [USER] su questione immigrazione/lavoratori afri...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Loose matched 'Chi attacca [USER] su questione immigraz...' -> tokens[24:26]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 136/231: 1261\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 137/231: 693\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 138/231: 111\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 139/231: 948\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 140/231: 1422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 141/231: 1298\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 142/231: 1347\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 143/231: 928\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 144/231: 807\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 145/231: 71\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 146/231: 345\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 147/231: 1370\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"E odg del M5S approvato ad ottobre e mai applicato da [USER] [URL] cari giornalisti fate un articolo su questo, se avete coraggio\", \"label\": \"Vagueness\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Vagueness] \"E odg del M5S approvato ad ottobre e mai applicato da [USER]...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Fuzzy matched (0.87) 'E odg del M5S approvato ad ottobre e mai...' -> tokens[6:29]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 148/231: 1061\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 149/231: 673\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 150/231: 130\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 151/231: 983\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"[URL]\", \"label\": \"Red-herring\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Red-herring] \"[URL]...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Matched '[URL]...' -> tokens[42:43]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 152/231: 1074\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 153/231: 420\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"P.S. Che dite,sentiremo il solito grida sdegnato di politici,giornalisti, radical chic e â€œintellettualiâ€ nostrani?\", \"label\": \"Thought-terminating-cliches\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Thought-terminating-cliches] \"P.S. Che dite,sentiremo il solito grida sdegnato di politici...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " FAILED to match: 'P.S. Che dite,sentiremo il solito grida sdegnato d...'\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 154/231: 591\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"4 anni fa, oggi, il problema principale del Paese erano i sacchetti biodegradabili a 0,05 centesimi. Compresa la bufala della cugina di [USER] che li produceva.\", \"label\": \"Red-herring\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Red-herring] \"4 anni fa, oggi, il problema principale del Paese erano i sa...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Fuzzy matched (0.54) '4 anni fa, oggi, il problema principale ...' -> tokens[2:28]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 155/231: 577\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Penso ci sia un piccolo problema di cambiamento climatico. Ma forse eh.\", \"label\": \"Hasty-generalization\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Hasty-generalization] \"Penso ci sia un piccolo problema di cambiamento climatico. M...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Fuzzy matched (0.75) 'Penso ci sia un piccolo problema di camb...' -> tokens[7:19]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 156/231: 1060\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Togliersi la mascherina in Parlamento mentre critichi le misure del Governo in tempo di grave pandemia mondiale.  Ecco il livello dell'opposizione in Italia. [URL]\", \"label\": \"Evading-the-burden-of-proof\"}}\n",
      "  ...\n",
      " JSON array parsing failed: Unterminated string starting at: line 1 column 11 (char 10)\n",
      " JSON object parsing failed: Expecting ',' delimiter: line 1 column 227 (char 226)\n",
      "  â†’ Trying line-by-line extraction...\n",
      " Extracted 1 spans line-by-line\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Evading-the-burden-of-proof] \"Togliersi la mascherina in Parlamento mentre critichi le mis...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Fuzzy matched (0.71) 'Togliersi la mascherina in Parlamento me...' -> tokens[0:24]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 157/231: 234\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 158/231: 742\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Allâ€™on. [USER] che chiede di aprire il Parlamento (mai chiuso in realtÃ ) io chiedo: ci prometti che poi vieni?\", \"label\": \"Thought-terminating-cliches\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Thought-terminating-cliches] \"Allâ€™on. [USER] che chiede di aprire il Parlamento (mai chius...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Loose matched 'Allâ€™on. [USER] che chiede di aprire il P...' -> tokens[2:24]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 159/231: 216\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"hey #PutinWarCriminal il #ClimateCrisis ha fatto anche cose buone ðŸ–•ðŸ˜ 25 gradi ad Ottobre ðŸ˜ðŸ–• [URL]\", \"label\": \"Vagueness\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Vagueness] \"hey #PutinWarCriminal il #ClimateCrisis ha fatto anche cose ...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Fuzzy matched (0.50) 'hey #PutinWarCriminal il #ClimateCrisis ...' -> tokens[2:18]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 160/231: 349\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 161/231: 1319\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Si, penso sia qualcosa di cui tutti dovremmo preoccuparci, al momento.\", \"label\": \"Vagueness\"}, {\"text\": \"Sembra una cosa difficile da fare,ma in realtÃ  richiede poco sforzo.\", \"label\": \"Causal-oversimplification\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 2 spans:\n",
      "    - [Vagueness] \"Si, penso sia qualcosa di cui tutti dovremmo preoccuparci, a...\"\n",
      "    - [Causal-oversimplification] \"Sembra una cosa difficile da fare,ma in realtÃ  richiede poco...\"\n",
      "\n",
      "  Converting 2 spans to BIO tags...\n",
      " Fuzzy matched (0.82) 'Si, penso sia qualcosa di cui tutti dovr...' -> tokens[3:14]\n",
      " Fuzzy matched (0.55) 'Sembra una cosa difficile da fare,ma in ...' -> tokens[25:36]\n",
      "   BIO validation passed: 2 spans\n",
      "\n",
      "Processing post 162/231: 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 163/231: 733\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"se Salvini non fa sbarcare gli immigrati per 4 g, per il controllo dei documenti, Ã¨ sequestro di persona 2) se la Lamorgese non li fa sbarcare per 11 g, perchÃ© ci sono le elecciones, nessuno dice niente. E ancora crediamo che la legge sia uguale per tutti! Che paese di merda!\", \"label\": \"False-dilemma\"}}\n",
      "  ...\n",
      " JSON object parsing failed: Expecting ',' delimiter: line 1 column 326 (char 325)\n",
      "  â†’ Trying line-by-line extraction...\n",
      " Extracted 1 spans line-by-line\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [False-dilemma] \"se Salvini non fa sbarcare gli immigrati per 4 g, per il con...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Loose matched 'se Salvini non fa sbarcare gli immigrati...' -> tokens[2:47]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 164/231: 548\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 165/231: 445\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"â€œNo GreenPass, non ci facciamo bucare, piuttosto espatrio, BLOCCHIAMO I TRENIâ€ ecc, ci saranno sempre piÃ¹ vaccinati in segreto, per non perdere lâ€™assegno, ma che continueranno a far finta di â€œMAI il vaccino di BigFarmaâ€ \", \"label\": \"Evading-the-burden-of-proof\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Evading-the-burden-of-proof] \"â€œNo GreenPass, non ci facciamo bucare, piuttosto espatrio, B...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Loose matched 'â€œNo GreenPass, non ci facciamo bucare, p...' -> tokens[9:23]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 166/231: 1099\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Come i loro compari collaborazionisti del #PD, la loro parola vale meno di una scoreggia.\", \"label\": \"Name-calling-or-labelling\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Name-calling-or-labelling] \"Come i loro compari collaborazionisti del #PD, la loro parol...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Fuzzy matched (0.67) 'Come i loro compari collaborazionisti de...' -> tokens[26:41]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 167/231: 759\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 168/231: 899\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 169/231: 271\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"â¤ï¸\", \"label\": \"Flag-waving\"}, {\"text\": \"[URL]\", \"label\": \"Flag-waving\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 2 spans:\n",
      "    - [Flag-waving] \"â¤ï¸...\"\n",
      "    - [Flag-waving] \"[URL]...\"\n",
      "\n",
      "  Converting 2 spans to BIO tags...\n",
      " Matched 'â¤ï¸...' -> tokens[44:45]\n",
      " Matched '[URL]...' -> tokens[54:55]\n",
      "   BIO validation passed: 2 spans\n",
      "\n",
      "Processing post 170/231: 847\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 171/231: 508\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 172/231: 1299\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 173/231: 1384\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Forse perchÃ© x ogni minorenne affidato la retta minima giornaliera, pagata da comuni e aziende ospedaliere, Ã¨ di 200â‚¬, ma puÃ² arrivare anche a 400â‚¬?\", \"label\": \"Vagueness\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Vagueness] \"Forse perchÃ© x ogni minorenne affidato la retta minima giorn...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Loose matched 'Forse perchÃ© x ogni minorenne affidato l...' -> tokens[9:31]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 174/231: 867\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Ascolteremo?\", \"label\": \"Thought-terminating-cliches\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Thought-terminating-cliches] \"Ascolteremo?...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Fuzzy matched (1.00) 'Ascolteremo?...' -> tokens[8:9]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 175/231: 1192\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Il Cara di #Bari non Ã¨ piÃ¹ solo un Centro di accoglienza per richiedenti asilo, ma la base della #MAFIA nigeriana, da qui che i boss organizzavano il loro business Eâ€™ questa lâ€™altra medaglia dellâ€™#immigrazione, quella che i benpensanti e buonisti  si ostinano a non voler vedere\", \"label\": \"Strawman\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Strawman] \"Il Cara di #Bari non Ã¨ piÃ¹ solo un Centro di accoglienza per...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Loose matched 'Il Cara di #Bari non Ã¨ piÃ¹ solo un Centr...' -> tokens[0:48]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 176/231: 1320\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 177/231: 773\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Io penso meglio piuttosto che niente.\", \"label\": \"Flag-waving\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Flag-waving] \"Io penso meglio piuttosto che niente....\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Fuzzy matched (1.00) 'Io penso meglio piuttosto che niente....' -> tokens[48:54]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 178/231: 229\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 179/231: 1043\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 180/231: 128\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 181/231: 1375\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 182/231: 107\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"La sintesi di [USER] Non servono altre parole a questo strazio #migranti #HumanRights [URL]\", \"label\": \"Vagueness\"}}]\n",
      "  ...\n",
      " JSON array parsing failed: Expecting ',' delimiter: line 1 column 127 (char 126)\n",
      " JSON object parsing failed: Expecting ',' delimiter: line 1 column 137 (char 136)\n",
      "  â†’ Trying line-by-line extraction...\n",
      " Extracted 1 spans line-by-line\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Vagueness] \"La sintesi di [USER] Non servono altre parole a questo straz...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Fuzzy matched (0.86) 'La sintesi di [USER] Non servono altre p...' -> tokens[0:14]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 183/231: 972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 184/231: 1086\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Se #Renzi salisse sulla #SeaWatch , sono sicuro che parte della sinistra si schiererebbe con #Salvini per affondare la nave con tutti i migranti. #Scendeteli\", \"label\": \"Slippery-slope\"}}\n",
      "  ...\n",
      " JSON object parsing failed: Expecting ',' delimiter: line 1 column 208 (char 207)\n",
      "  â†’ Trying line-by-line extraction...\n",
      " Extracted 1 spans line-by-line\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Slippery-slope] \"Se #Renzi salisse sulla #SeaWatch , sono sicuro che parte de...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Fuzzy matched (0.56) 'Se #Renzi salisse sulla #SeaWatch , sono...' -> tokens[2:27]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 185/231: 1182\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"''I migranti ci tolgono il pane''. - Antonio Gallardo, coordinatore di Vox - [URL]\", \"label\": \"Thought-terminating-cliches\"}}]\n",
      "  ...\n",
      " JSON array parsing failed: Expecting ',' delimiter: line 1 column 136 (char 135)\n",
      " JSON object parsing failed: Expecting ',' delimiter: line 1 column 146 (char 145)\n",
      "  â†’ Trying line-by-line extraction...\n",
      " Extracted 1 spans line-by-line\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Thought-terminating-cliches] \"''I migranti ci tolgono il pane''. - Antonio Gallardo, coord...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Loose matched '''I migranti ci tolgono il pane''. - Ant...' -> tokens[1:18]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 186/231: 1230\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 187/231: 955\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 188/231: 652\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 189/231: 788\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"alla faccia dell'accordo di #Malta. alla faccia del finto buonismo #europeo #26luglio\", \"label\": \"Strawman\"}, {\"text\": \"[URL]\", \"label\": \"Slogan\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 2 spans:\n",
      "    - [Strawman] \"alla faccia dell'accordo di #Malta. alla faccia del finto bu...\"\n",
      "    - [Slogan] \"[URL]...\"\n",
      "\n",
      "  Converting 2 spans to BIO tags...\n",
      " Fuzzy matched (0.58) 'alla faccia dell'accordo di #Malta. alla...' -> tokens[42:54]\n",
      " Matched '[URL]...' -> tokens[56:57]\n",
      "   BIO validation passed: 2 spans\n",
      "\n",
      "Processing post 190/231: 974\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 191/231: 23\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"PoichÃ© Ã¨ un #senatore della #repubblica #Salvini va difeso e non preso in giro\", \"label\": \"Thought-terminating-cliches\"}, {\"text\": \"Si ricordino pure di quando #derideva e #insultava i #terroni, gli #immigrati, gli #LGBTQ\", \"label\": \"Thought-terminating-cliches\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 2 spans:\n",
      "    - [Thought-terminating-cliches] \"PoichÃ© Ã¨ un #senatore della #repubblica #Salvini va difeso e...\"\n",
      "    - [Thought-terminating-cliches] \"Si ricordino pure di quando #derideva e #insultava i #terron...\"\n",
      "\n",
      "  Converting 2 spans to BIO tags...\n",
      " Fuzzy matched (0.71) 'PoichÃ© Ã¨ un #senatore della #repubblica ...' -> tokens[14:28]\n",
      " Fuzzy matched (0.64) 'Si ricordino pure di quando #derideva e ...' -> tokens[39:53]\n",
      "   BIO validation passed: 2 spans\n",
      "\n",
      "Processing post 192/231: 138\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 193/231: 1287\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 194/231: 416\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 195/231: 282\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 196/231: 324\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Non vaccinatevi perchÃ© questo falso vaccino abbassa le difese immunitarie e se abbiamo qualche problema di salute questo prende il sopravvento e ci manda ðŸ’€\", \"label\": \"False-dilemma\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [False-dilemma] \"Non vaccinatevi perchÃ© questo falso vaccino abbassa le difes...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Matched 'Non vaccinatevi perchÃ© questo falso vacc...' -> tokens[23:48]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 197/231: 986\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"\\\"Ãˆ ufficiale: \\\"poco piÃ¹ di un influenza\\\"  Ã¨ diventata una #pandemia. Informate l'esercito degli involtini primavera\\\"\", \"label\": \"None\"}}\n",
      "  ...\n",
      " JSON object parsing failed: Expecting ',' delimiter: line 1 column 161 (char 160)\n",
      "  â†’ Trying line-by-line extraction...\n",
      " Extracted 1 spans line-by-line\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 198/231: 1156\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 199/231: 1169\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Con il #Conte2 si torna al â€œpatto Boninoâ€ sui #migranti: lâ€™Italia li accoglie tutti e ridiventa il campo profughi dâ€™Europa, la #UE ricollocherÃ  il 25% degli aventi diritto allâ€™asilo, meno del 15% del totale.  Grazie [USER] ! â€œObiettivo sbarchi zeroâ€ raggiunto come promesso!\", \"label\": \"Red-herring\"}}\n",
      "  ...\n",
      " JSON array parsing failed: Unterminated string starting at: line 1 column 11 (char 10)\n",
      " JSON object parsing failed: Expecting ',' delimiter: line 1 column 322 (char 321)\n",
      "  â†’ Trying line-by-line extraction...\n",
      " Extracted 1 spans line-by-line\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Red-herring] \"Con il #Conte2 si torna al â€œpatto Boninoâ€ sui #migranti: lâ€™I...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Loose matched 'Con il #Conte2 si torna al â€œpatto Bonino...' -> tokens[0:21]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 200/231: 521\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 201/231: 1243\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"#renzi: \"le nostre battaglie in UE non erano per il bene dell'Italia ma dell'Europa\" #bonino: \"abbiamo chiesto noi di far sbarcare tutti in Italia\" #gentiloni: \"dobbiamo accoglierli perchÃ¨ scappano dai cambiamenti climatici\", \"label\": \"Slippery-slope\"}]}\n",
      "  ...\n",
      " JSON array parsing failed: Expecting ',' delimiter: line 1 column 21 (char 20)\n",
      " JSON object parsing failed: Expecting ',' delimiter: line 1 column 31 (char 30)\n",
      "  â†’ Trying line-by-line extraction...\n",
      " Extracted 1 spans line-by-line\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Slippery-slope] \"#renzi:...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Fuzzy matched (1.00) '#renzi:...' -> tokens[9:10]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 202/231: 438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 203/231: 783\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Quindi?\", \"label\": \"Slogan\"}, {\"text\": \"In certe parti del mondo sono normali pure lapidazione, legge del taglione, spose bambine.\", \"label\": \"Slippery-slope\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 2 spans:\n",
      "    - [Slogan] \"Quindi?...\"\n",
      "    - [Slippery-slope] \"In certe parti del mondo sono normali pure lapidazione, legg...\"\n",
      "\n",
      "  Converting 2 spans to BIO tags...\n",
      " Fuzzy matched (1.00) 'Quindi?...' -> tokens[36:37]\n",
      " Fuzzy matched (0.64) 'In certe parti del mondo sono normali pu...' -> tokens[36:50]\n",
      "   BIO validation passed: 2 spans\n",
      "\n",
      "Processing post 204/231: 1015\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Si puÃ² essere piÃ¹ infami?\", \"label\": \"Thought-terminating-cliches\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Thought-terminating-cliches] \"Si puÃ² essere piÃ¹ infami?...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Fuzzy matched (1.00) 'Si puÃ² essere piÃ¹ infami?...' -> tokens[17:22]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 205/231: 82\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Prima gli italiani ma solo se imprenditori ed evasori fiscali\", \"label\": \"Thought-terminating-cliches\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Thought-terminating-cliches] \"Prima gli italiani ma solo se imprenditori ed evasori fiscal...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Matched 'Prima gli italiani ma solo se imprendito...' -> tokens[34:44]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 206/231: 1078\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 207/231: 1163\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 208/231: 536\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 209/231: 751\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Con la scusa della epidemia vogliono regolarizzare subito 600 mila immigrati irregolari. Come se la sanatoria fosse per loro un vaccino. Allora sarebbe invasione. Dicono â€œtanto le nostre frontiere sono chiuseâ€.Chiuse un tubo.\", \"label\": \"False-dilemma\"}, {\"text\": \"Dicono â€œtanto le nostre frontiere sono chiuseâ€.Chiuse un tubo.\", \"label\": \"False-dilemma\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 2 spans:\n",
      "    - [False-dilemma] \"Con la scusa della epidemia vogliono regolarizzare subito 60...\"\n",
      "    - [False-dilemma] \"Dicono â€œtanto le nostre frontiere sono chiuseâ€.Chiuse un tub...\"\n",
      "\n",
      "  Converting 2 spans to BIO tags...\n",
      " Loose matched 'Con la scusa della epidemia vogliono reg...' -> tokens[0:13]\n",
      " Fuzzy matched (0.78) 'Dicono â€œtanto le nostre frontiere sono c...' -> tokens[28:37]\n",
      "   BIO validation passed: 2 spans\n",
      "\n",
      "Processing post 210/231: 893\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 211/231: 918\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"cito, â€œlâ€™anidride carbonica secondo te sale o scende?â€\", \"label\": \"False-dilemma\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [False-dilemma] \"cito, â€œlâ€™anidride carbonica secondo te sale o scende?â€...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Fuzzy matched (0.88) 'cito, â€œlâ€™anidride carbonica secondo te s...' -> tokens[21:29]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 212/231: 1403\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 213/231: 1327\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 214/231: 431\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 215/231: 1351\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 216/231: 1265\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 217/231: 997\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 218/231: 87\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"\\\"Ãˆ lâ€™una di notte e 80 bambini stanno morendo su una barca con 250 persone che chiedono aiuto\\\" E forse non sono bastate le lacrime dei 4 bambini morti di sete in questi giorni. Ãˆ lâ€™una di notte e lâ€™umanitÃ  muore con questi bambini [USER] #migranti [URL]\", \"label\": \"Slippery-slope\"}}\n",
      "  ...\n",
      " JSON array parsing failed: Unterminated string starting at: line 1 column 11 (char 10)\n",
      " JSON object parsing failed: Expecting ',' delimiter: line 1 column 306 (char 305)\n",
      "  â†’ Trying line-by-line extraction...\n",
      " Extracted 1 spans line-by-line\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Slippery-slope] \"\\...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " FAILED to match: '\\...'\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 219/231: 1429\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 220/231: 361\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 221/231: 166\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 222/231: 1017\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"Ma lâ€™ha detto davvero? Dico, davvero Gallera ha detto che ringrazia i privati â€œperchÃ© hanno aperto le loro terapie intensive e le loro stanze lussuose ai pazienti ordinariâ€? Tralasciando le stanze â€œlussuoseâ€, ma davvero, secondo Gallera, esistono pazienti di diverse categorie?\", \"label\": \"Strawman\"}}\n",
      "  ...\n",
      " JSON object parsing failed: Expecting ',' delimiter: line 1 column 322 (char 321)\n",
      "  â†’ Trying line-by-line extraction...\n",
      " Extracted 1 spans line-by-line\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Strawman] \"Ma lâ€™ha detto davvero? Dico, davvero Gallera ha detto che ri...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Loose matched 'Ma lâ€™ha detto davvero? Dico, davvero Gal...' -> tokens[0:6]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 223/231: 1276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 224/231: 1350\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 225/231: 474\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"rifugiatevi nelle chiese!\", \"label\": \"Thought-terminating-cliches\"}]}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Thought-terminating-cliches] \"rifugiatevi nelle chiese!...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Fuzzy matched (1.00) 'rifugiatevi nelle chiese!...' -> tokens[6:9]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Processing post 226/231: 845\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 227/231: 713\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 228/231: 975\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 229/231: 878\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 230/231: 1335\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": []}\n",
      "  ...\n",
      " Extracted from JSON array\n",
      " Extracted from JSON object\n",
      "  â†’ Trying line-by-line extraction...\n",
      "\n",
      "  Extracted 0 spans:\n",
      "\n",
      "  Converting 0 spans to BIO tags...\n",
      "   BIO validation passed: 0 spans\n",
      "\n",
      "Processing post 231/231: 1201\n",
      "\n",
      "  MODEL RESPONSE (first 500 chars):\n",
      "  {\"spans\": [{\"text\": \"#Bolsonaro regala l'Amazzonia agli speculatori che la disboscheranno, il polmone verde del mondo muore ed a cascata la desertificazione  ed il pianeta Ã¨ fottuto con qualche miliardo di anni d'anticipo! PerÃ²  sparirÃ  il communismo!! contenti voi #facciamorete #14gennaio\", \"label\": \"Slippery-slope\"}}\n",
      "  ...\n",
      " JSON object parsing failed: Expecting ',' delimiter: line 1 column 320 (char 319)\n",
      "  â†’ Trying line-by-line extraction...\n",
      " Extracted 1 spans line-by-line\n",
      "\n",
      "  Extracted 1 spans:\n",
      "    - [Slippery-slope] \"#Bolsonaro regala l'Amazzonia agli speculatori che la disbos...\"\n",
      "\n",
      "  Converting 1 spans to BIO tags...\n",
      " Fuzzy matched (0.61) '#Bolsonaro regala l'Amazzonia agli specu...' -> tokens[3:41]\n",
      "   BIO validation passed: 1 spans\n",
      "\n",
      "Predictions saved to: ../results/subtask-b/Qwen_Qwen2.5-3B-Instruct_predicted.tsv\n",
      "\n",
      "Writing gold labels...\n",
      "Gold labels saved to: ../results/subtask-b/Qwen_Qwen2.5-3B-Instruct_gold.tsv\n",
      "\n",
      "============================================================\n",
      "RUNNING EVALUATION - SUBTASK B\n",
      "============================================================\n",
      "============================================================\n",
      "Evaluation for subtask \"B\".\n",
      "- Gold answers: ../results/subtask-b/Qwen_Qwen2.5-3B-Instruct_gold.tsv\n",
      "- Predictions:  ../results/subtask-b/Qwen_Qwen2.5-3B-Instruct_predicted.tsv\n",
      "============================================================\n",
      "Labels for the task: Ad-hominem; Appeal-to-authority; Appeal-to-emotion; Causal-oversimplification; Cherry-picking; Circular-reasoning; Doubt; Evading-the-burden-of-proof; False-analogy; False-dilemma; Flag-waving; Hasty-generalization; Loaded-language; Name-calling-or-labelling; Red-herring; Slippery-slope; Slogan; Strawman; Thought-terminating-cliches; Vagueness; O\n",
      "============================================================\n",
      "[Note to participants]: as mentioned in the 'Submission format' section in the GitHub repository \n",
      "(https://github.com/dhfbk/fadeit-evalita2026), you should ensure the following in your prediction \n",
      "files to avoid any issues (and for propering evaluating the performance of your system):\n",
      "  1) The order of the posts in the prediction and gold files should be the same;\n",
      "  2) The predicted labels should be the ones in the train/dev data (ordered lexicographically);\n",
      "  3) If your system produces a single prediction for each post, just write the same predictions on \n",
      "     both prediction columns. O.w., print the different predictions to the corresponding columns;\n",
      "  4) For subtask A only: a header line should be included in the prediction file.\n",
      "============================================================\n",
      "Getting the span annotations...\n",
      "- Predictions:  202 (a1: 101; a2: 101)\n",
      "- Gold answers: 1725 (a1: 818; a2: 907)\n",
      "-> Done.\n",
      "============================================================\n",
      "Computing scores...\n",
      "[strict evaluation]\n",
      "  \tprec\trec\tf1\n",
      "a1\t6.8\t1.4\t2.32\n",
      "a2\t3.55\t1.14\t1.73\n",
      "avg\t5.17\t1.27\t2.02\n",
      "------------------------------------------------------------\n",
      "[soft evaluation]\n",
      "  \tprec\trec\tf1\n",
      "a1\t9.66\t1.83\t3.07\n",
      "a2\t5.06\t1.31\t2.09\n",
      "avg\t7.36\t1.57\t2.58\n",
      "-> Done.\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    CONLL_PATH = \"../data/faina-v1.0_fadeit-shared-task/faina-v1.0_fadeit-shared-task/data/subtask-b/train-dev.conll\"\n",
    "    safe_model_name = Model_Name.replace(\"/\", \"_\")\n",
    "    PRED_PATH = f\"../results/subtask-b/{safe_model_name}_predicted.tsv\"\n",
    "    GOLD_PATH = f\"../results/subtask-b/{safe_model_name}_gold.tsv\"\n",
    "    \n",
    "    \n",
    "    print(\"Initializing span extractor...\")\n",
    "    model, tokenizer, device = init_model(use_4bit=True)\n",
    "    \n",
    "    print(\"\\nParsing CoNLL file...\")\n",
    "    all_posts = parse_conll_file(CONLL_PATH)\n",
    "    \n",
    "    train_posts, test_posts = train_test_split(\n",
    "        all_posts, test_size=0.2, random_state=42, shuffle=True\n",
    "    )\n",
    "    print(f\"\\nTrain: {len(train_posts)} posts\")\n",
    "    print(f\"Test: {len(test_posts)} posts\")\n",
    "    \n",
    "    print(\"\\nBuilding few-shot examples...\")\n",
    "    examples = build_few_shot_examples(train_posts, n_examples_per_label=3, annotator=\"a1\")\n",
    "    \n",
    "    print(\"\\nGenerating predictions...\")\n",
    "    write_conll_predictions(test_posts, PRED_PATH, examples, model, tokenizer, device)\n",
    "    \n",
    "    print(\"\\nWriting gold labels...\")\n",
    "    with open(GOLD_PATH, 'w', encoding='utf-8') as f:\n",
    "        for post in test_posts:\n",
    "            f.write(f\"# post_id = {post['post_id']}\\n\")\n",
    "            f.write(f\"# post_date = {post['date']}\\n\")\n",
    "            f.write(f\"# post_topic_keywords = {post['topic']}\\n\")\n",
    "            f.write(f\"# post_text = {post['text']}\\n\")\n",
    "            for tok_idx, (token, bio_a1, bio_a2) in enumerate(zip(\n",
    "                post['tokens'], post['bio_tags_a1'], post['bio_tags_a2']\n",
    "            ), start=1):\n",
    "                f.write(f\"{tok_idx}\\t{token}\\t{bio_a1}\\t{bio_a2}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "    \n",
    "    print(f\"Gold labels saved to: {GOLD_PATH}\")    \n",
    "    evaluate(GOLD_PATH, PRED_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5133dcf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fadeit",
   "language": "python",
   "name": "fadeit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
